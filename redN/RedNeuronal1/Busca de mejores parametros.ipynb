{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PcR\\AppData\\Local\\Temp\\ipykernel_5736\\3118260604.py:25: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from tensorflow import keras\n",
    "from kerastuner import RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "En Red con max ya se logró una red que predice los valores máximos de longitud de onda e índice de absorción. Esta red no nada más predecirá elñ punto máximo sinó que buscaremos que prediga todo el espectro de longitudes de onda, es decir de 300 a 900nm. Como resultado esperamos una gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir('./parametros')]\n",
    "\n",
    "param = pd.DataFrame()\n",
    "for file in files:\n",
    "  df = pd.read_csv('./parametros/'+file)\n",
    "  param = pd.concat([param, df], axis= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir los datos en características (X) y etiquetas (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Índice de absorción', axis=1).values\n",
    "y = df['Índice de absorción'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar los datos usando MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "y_normalized = scaler.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit(X)\n",
    "X_normalized = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir los datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intento con Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 39s]\n",
      "val_loss: 8.604404418595853e-07\n",
      "\n",
      "Best val_loss So Far: 4.578553169191461e-07\n",
      "Total elapsed time: 00h 03m 16s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Capa de entrada\n",
    "    model.add(keras.layers.Dense(units=hp.Int('input_units', min_value=4, max_value=128, step=32),\n",
    "                                 input_dim=4, \n",
    "                                 kernel_initializer='normal', \n",
    "                                 activation='relu'))\n",
    "    \n",
    "    # Capa oculta\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden_units', min_value=4, max_value=128, step=32),\n",
    "                                 kernel_initializer='normal', \n",
    "                                 activation='relu'))\n",
    "    \n",
    "    # Capa de salida\n",
    "    model.add(keras.layers.Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    # Compilación\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Definir el buscador\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,  # Número de combinaciones de hiperparámetros para probar\n",
    "    executions_per_trial=3,  # Número de veces que se entrena cada modelo\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')\n",
    "\n",
    "# Cuando estés listo para buscar los mejores hiperparámetros, ejecuta:\n",
    "tuner.search(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intento con GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate Deep ANN model \n",
    "def make_regression_ann(Optimizer_trial):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=5, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=64, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Optimizer_trial)\n",
    "    return model\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "# Listing all the parameters to try\n",
    "Parameter_Trials={'batch_size':[10],'epochs':[50,200],'Optimizer_trial':['adam'], 'validation_split' : [0.05, 0.1, 0.06,0.07]}\n",
    "\n",
    "# Creating the regression ANN model\n",
    "RegModel=KerasRegressor(make_regression_ann, verbose=0)\n",
    "\n",
    "###########################################\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Defining a custom function to calculate accuracy\n",
    "def Accuracy_Score(orig,pred):\n",
    "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
    "    print('#'*70,'Accuracy:', 100-MAPE)\n",
    "    return(100-MAPE)\n",
    "\n",
    "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n",
    "\n",
    "#########################################\n",
    "# Creating the Grid search space\n",
    "# See different scoring methods by using sklearn.metrics.SCORERS.keys()\n",
    "grid_search=GridSearchCV(estimator=RegModel, \n",
    "                         param_grid=Parameter_Trials, \n",
    "                         scoring=custom_Scoring, \n",
    "                         cv=5)\n",
    "\n",
    "#########################################\n",
    "# Measuring how much time it took to find the best params\n",
    "import time\n",
    "StartTime=time.time()\n",
    "\n",
    "# Running Grid Search for different paramenters\n",
    "grid_search.fit(X,y, verbose=1)\n",
    "\n",
    "EndTime=time.time()\n",
    "print(\"########## Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes')\n",
    "\n",
    "print('### Printing Best parameters ###')\n",
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
